# -*- coding: utf-8 -*-
"""analisadorvoz3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lQG1wSewIPpk3vhAld198M_SsdK2zMvB
"""

# ============================================================================
# EXTRA√á√ÉO DE VOCAIS - Amy Winehouse
# Google Colab - C√≥digo Simplificado
# ============================================================================

# CELL 1: Instala√ß√£o de depend√™ncias
# ----------------------------------------------------------------------------
!pip install -q yt-dlp demucs librosa soundfile
!apt-get install -q -y ffmpeg

# CELL 2: Configurar Google Drive
# ----------------------------------------------------------------------------
from google.colab import drive
drive.mount('/content/drive')

import os

# Diret√≥rio para salvar os √°udios
DRIVE_OUTPUT_PATH = '/content/drive/MyDrive/AudioAnalysis/AmyWinehouse'
os.makedirs(DRIVE_OUTPUT_PATH, exist_ok=True)
print(f"‚úì Diret√≥rio criado: {DRIVE_OUTPUT_PATH}")

# Diret√≥rio tempor√°rio
TEMP_DIR = "/content/temp_audio"
os.makedirs(TEMP_DIR, exist_ok=True)

# CELL 3: Imports
# ----------------------------------------------------------------------------
import subprocess
import shutil
import torch
from demucs.pretrained import get_model
from demucs.apply import apply_model
from demucs.audio import AudioFile, save_audio

# CELL 4: Fun√ß√£o para baixar m√∫sica do YouTube
# ----------------------------------------------------------------------------
def download_audio(url, output_path):
    """
    Baixa √°udio do YouTube em alta qualidade
    """
    print(f"üì• Baixando √°udio de: {url}")

    os.makedirs(output_path, exist_ok=True)

    try:
        ytdlp_path = shutil.which('yt-dlp')

        if not ytdlp_path:
            print("‚ùå yt-dlp n√£o encontrado. Instalando...")
            subprocess.run(['pip', 'install', '-U', 'yt-dlp'], check=True)
            ytdlp_path = shutil.which('yt-dlp')

        output_template = os.path.join(output_path, 'audio.%(ext)s')

        cmd = [
            ytdlp_path,
            '-x',  # Extrair √°udio
            '--audio-format', 'wav',
            '--audio-quality', '0',  # Melhor qualidade
            '-o', output_template,
            '--no-playlist',
            '--no-check-certificate',
            '--prefer-ffmpeg',
            url
        ]

        print("Executando download...")
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)

        if result.returncode == 0:
            # Procurar arquivo .wav baixado
            wav_files = [f for f in os.listdir(output_path) if f.endswith('.wav')]
            if wav_files:
                audio_file = os.path.join(output_path, wav_files[0])
                file_size = os.path.getsize(audio_file) / (1024 * 1024)
                print(f"‚úì Download conclu√≠do: {file_size:.2f} MB")
                return audio_file

        print(f"‚ùå Erro no download")
        print(f"STDERR: {result.stderr}")
        return None

    except subprocess.TimeoutExpired:
        print("‚ùå Timeout: Download demorou muito")
        return None
    except Exception as e:
        print(f"‚ùå Erro ao baixar: {e}")
        return None

# CELL 5: Fun√ß√£o para separar vocais usando Demucs
# ----------------------------------------------------------------------------
def separate_vocals(audio_path, output_dir):
    """
    Separa a voz do acompanhamento musical usando Demucs
    """
    if not audio_path or not os.path.exists(audio_path):
        print(f"‚ùå Arquivo de √°udio inv√°lido: {audio_path}")
        return None

    print("üéµ Separando voz do acompanhamento com Demucs...")
    print("   (Pode demorar 3-5 minutos)")

    try:
        # Criar diret√≥rio de sa√≠da
        os.makedirs(output_dir, exist_ok=True)

        # Determinar dispositivo (CPU ou GPU)
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"   Dispositivo: {device}")

        # Carregar modelo Demucs
        print("   Carregando modelo...")
        model = get_model('htdemucs_ft')
        model.to(device)
        model.eval()

        # Carregar √°udio
        print("   Processando √°udio...")
        wav = AudioFile(audio_path).read(
            streams=0,
            samplerate=model.samplerate,
            channels=model.audio_channels
        )

        # Normalizar
        ref = wav.mean(0)
        wav = (wav - ref.mean()) / ref.std()

        # Mover para dispositivo
        wav = wav.to(device).unsqueeze(0)

        # Separar stems
        print("   Separando vocais...")
        with torch.no_grad():
            sources = apply_model(
                model, wav,
                device=device,
                shifts=1,
                split=True,
                overlap=0.25
            )

        # Extrair vocais (√≠ndice 3: vocals)
        vocals = sources[0, 3]

        # Desnormalizar
        vocals = vocals * ref.std() + ref.mean()

        # Salvar arquivo de vocais
        vocals_output = os.path.join(output_dir, 'vocals.wav')
        save_audio(
            vocals.cpu(),
            vocals_output,
            samplerate=model.samplerate
        )

        if os.path.exists(vocals_output):
            file_size = os.path.getsize(vocals_output) / (1024 * 1024)
            print(f"‚úì Vocais separados: {file_size:.2f} MB")
            return vocals_output
        else:
            print("‚ùå Erro ao salvar vocais")
            return None

    except Exception as e:
        print(f"‚ùå Erro no Demucs: {e}")
        import traceback
        traceback.print_exc()
        return None

# CELL 6: Pipeline completo
# ----------------------------------------------------------------------------
def process_audio(youtube_url, track_name):
    """
    Pipeline completo: Download -> Separa√ß√£o -> Salvar
    """
    print("\n" + "="*70)
    print(f"üéµ PROCESSANDO: {track_name}")
    print("="*70 + "\n")

    # 1. Download do YouTube
    print("üì• Etapa 1/3: Download")
    audio_file = download_audio(youtube_url, TEMP_DIR)
    if not audio_file:
        print("‚ùå Falha no download")
        return None

    # 2. Separa√ß√£o de vocais
    print("\nüéµ Etapa 2/3: Separa√ß√£o de vocais")
    vocals_file = separate_vocals(audio_file, TEMP_DIR)
    if not vocals_file:
        print("‚ùå Falha na separa√ß√£o")
        return None

    # 3. Salvar no Google Drive
    print("\nüíæ Etapa 3/3: Salvando no Google Drive")
    filename = f"{track_name.replace(' ', '_')}_vocals.wav"
    output_path = os.path.join(DRIVE_OUTPUT_PATH, filename)

    shutil.copy2(vocals_file, output_path)

    file_size = os.path.getsize(output_path) / (1024 * 1024)
    print(f"‚úì Arquivo salvo: {output_path}")
    print(f"‚úì Tamanho: {file_size:.2f} MB")

    # Limpar arquivos tempor√°rios
    try:
        shutil.rmtree(TEMP_DIR)
        os.makedirs(TEMP_DIR, exist_ok=True)
    except:
        pass

    print("\n" + "="*70)
    print("‚úÖ PROCESSAMENTO CONCLU√çDO!")
    print("="*70)

    return output_path

# CELL 7: EXECUTAR - Back to Black
# ----------------------------------------------------------------------------
# Amy Winehouse - Back to Black
YOUTUBE_URL = "https://www.youtube.com/watch?v=TJAfLE39ZZ8"
TRACK = "Back_to_Black"

result = process_audio(YOUTUBE_URL, TRACK)

if result:
    print(f"\nüéµ Vocais salvos em: {result}")
else:
    print("\n‚ùå Erro no processamento")

"""
Sistema Completo de An√°lise Vocal para Replica√ß√£o de Cantores
C√≥digo Python para Google Colab - VERS√ÉO MELHORADA
Extrai letras e analisa TODAS as caracter√≠sticas vocais com relat√≥rio pr√°tico

INSTRU√á√ïES:
1. Copie todo este c√≥digo
2. Cole em uma c√©lula do Google Colab
3. Ajuste o AUDIO_PATH com o caminho do seu arquivo
4. Ajuste SEGMENTACAO_TEMPO para controlar granularidade da an√°lise
5. Execute a c√©lula
"""

# ============================================================================
# INSTALA√á√ÉO DE DEPEND√äNCIAS
# ============================================================================
print("üì¶ Instalando depend√™ncias...")

import os
import sys
import subprocess

def instalar_dependencias():
    subprocess.run([sys.executable, "-m", "pip", "install", "--upgrade", "pip"], check=True)

    pacotes = [
        "torch",
        "librosa",
        "pydub",
        "SpeechRecognition",
        "praat-parselmouth",
        "scipy",
        "openai-whisper"
    ]

    for pacote in pacotes:
        print(f"‚Üí Instalando {pacote}...")
        subprocess.run([sys.executable, "-m", "pip", "install", "-q", pacote], check=True)

    subprocess.run(["apt-get", "install", "-y", "-qq", "ffmpeg"], check=True)
    print("‚úì Depend√™ncias instaladas com sucesso!\n")

try:
    import whisper
    import librosa
    import parselmouth
except ImportError:
    instalar_dependencias()
    import whisper
    import librosa
    import parselmouth

print("‚úÖ Ambiente pronto para an√°lise vocal!")

# ============================================================================
# IMPORTAR BIBLIOTECAS
# ============================================================================
import whisper
import librosa
import numpy as np
from google.colab import drive
import torch
import parselmouth
from parselmouth.praat import call
from scipy import signal
from scipy.stats import kurtosis, skew
import json
import warnings
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

print("‚úì Bibliotecas importadas!")

# ============================================================================
# MONTAR GOOGLE DRIVE
# ============================================================================
print("\nüìÅ Montando Google Drive...")
drive.mount('/content/drive')
print("‚úì Drive montado!")

# ============================================================================
# CONFIGURA√á√ïES - AJUSTE AQUI!
# ============================================================================
print("\n‚öôÔ∏è Configura√ß√µes:")
print("="*80)

# CAMINHO DO ARQUIVO DE √ÅUDIO
AUDIO_PATH = '/content/drive/MyDrive/temp_audio/vocals_demucs.wav'

# MODELO WHISPER: 'tiny', 'base', 'small', 'medium', 'large'
MODEL_SIZE = 'medium'

# ‚≠ê NOVA CONFIGURA√á√ÉO: SEGMENTA√á√ÉO DE TEMPO ‚≠ê
# Define o tamanho m√°ximo de cada segmento para an√°lise detalhada
# Valores menores = an√°lise mais granular (detecta varia√ß√µes r√°pidas)
# Valores maiores = an√°lise mais geral (m√©dia de caracter√≠sticas)
SEGMENTACAO_TEMPO = 3.0  # segundos
# Exemplos:
#   1.0 = an√°lise palavra por palavra (muito detalhado)
#   3.0 = an√°lise por frase curta (recomendado)
#   5.0 = an√°lise por frase longa (mais geral)
#   10.0 = an√°lise por se√ß√£o musical

print(f"‚úì Arquivo: {AUDIO_PATH}")
print(f"‚úì Modelo Whisper: {MODEL_SIZE}")
print(f"‚úì Segmenta√ß√£o de tempo: {SEGMENTACAO_TEMPO}s (cada segmento ser√° analisado separadamente)")

if os.path.exists(AUDIO_PATH):
    print(f"‚úì Arquivo encontrado!")
    print(f"‚úì Tamanho: {os.path.getsize(AUDIO_PATH) / (1024*1024):.2f} MB")
else:
    print(f"‚ùå ERRO: Arquivo n√£o encontrado!")
    print(f"   Ajuste o AUDIO_PATH no c√≥digo.")

print("="*80)

# ============================================================================
# CLASSES DE AN√ÅLISE (mantidas do c√≥digo original)
# ============================================================================

class AnalisadorPitch:
    """Analisa F0, vibrato e caracter√≠sticas fundamentais de frequ√™ncia"""

    def __init__(self):
        self.hop_length = 512

    def extrair_f0(self, audio, sr):
        """Extrai frequ√™ncia fundamental (F0) usando YIN algorithm"""
        f0, voiced_flag, voiced_probs = librosa.pyin(
            audio,
            fmin=librosa.note_to_hz('C2'),
            fmax=librosa.note_to_hz('C7'),
            sr=sr
        )
        return f0, voiced_flag, voiced_probs

    def analisar_vibrato(self, f0, sr):
        """Analisa caracter√≠sticas do vibrato: taxa, extens√£o e regularidade"""
        f0_clean = f0[~np.isnan(f0)]

        if len(f0_clean) < 10:
            return {
                'taxa_hz': 0,
                'extensao_cents': 0,
                'regularidade': 0,
                'presente': False
            }

        fft = np.fft.fft(f0_clean - np.mean(f0_clean))
        freqs = np.fft.fftfreq(len(f0_clean), 1/sr * self.hop_length)

        mask = (freqs > 3) & (freqs < 10)
        if np.sum(mask) > 0:
            idx_max = np.argmax(np.abs(fft[mask]))
            taxa_vibrato = freqs[mask][idx_max]
        else:
            taxa_vibrato = 0

        if len(f0_clean) > 0:
            extensao = np.std(f0_clean) / np.mean(f0_clean) * 1200
        else:
            extensao = 0

        regularidade = 1 / (1 + np.std(np.diff(f0_clean)))

        return {
            'taxa_hz': float(taxa_vibrato),
            'extensao_cents': float(extensao),
            'regularidade': float(regularidade),
            'presente': taxa_vibrato > 3 and extensao > 20
        }

    def estatisticas_f0(self, f0):
        """Estat√≠sticas gerais do F0"""
        f0_clean = f0[~np.isnan(f0)]

        if len(f0_clean) == 0:
            return {'media': 0, 'mediana': 0, 'std': 0, 'min': 0, 'max': 0, 'range': 0}

        return {
            'media': float(np.mean(f0_clean)),
            'mediana': float(np.median(f0_clean)),
            'std': float(np.std(f0_clean)),
            'min': float(np.min(f0_clean)),
            'max': float(np.max(f0_clean)),
            'range': float(np.max(f0_clean) - np.min(f0_clean))
        }

class AnalisadorEspectral:
    """Analisa formantes, MFCC e envelope espectral"""

    def extrair_formantes(self, audio, sr, n_formantes=5):
        """Extrai formantes F1-F5 usando Praat"""
        try:
            snd = parselmouth.Sound(audio, sampling_frequency=sr)
            formants = call(snd, "To Formant (burg)", 0.0, n_formantes, 5500, 0.025, 50)

            formantes_valores = []
            for i in range(1, n_formantes + 1):
                formante_array = []
                for t in np.arange(0, snd.duration, 0.01):
                    try:
                        f = call(formants, "Get value at time", i, t, 'Hertz', 'Linear')
                        if not np.isnan(f):
                            formante_array.append(f)
                    except:
                        pass

                if formante_array:
                    formantes_valores.append({
                        f'F{i}_media': float(np.mean(formante_array)),
                        f'F{i}_std': float(np.std(formante_array)),
                        f'F{i}_min': float(np.min(formante_array)),
                        f'F{i}_max': float(np.max(formante_array))
                    })

            return formantes_valores
        except:
            return [{}] * n_formantes

    def extrair_mfcc(self, audio, sr, n_mfcc=13):
        """Extrai coeficientes MFCC"""
        mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=n_mfcc)

        mfcc_stats = {}
        for i in range(n_mfcc):
            mfcc_stats[f'mfcc_{i+1}_media'] = float(np.mean(mfccs[i]))
            mfcc_stats[f'mfcc_{i+1}_std'] = float(np.std(mfccs[i]))

        return mfcc_stats

    def analisar_envelope_espectral(self, audio, sr):
        """Analisa o envelope espectral"""
        stft = np.abs(librosa.stft(audio))
        envelope = np.mean(stft, axis=1)

        centroide = librosa.feature.spectral_centroid(y=audio, sr=sr)
        rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr, roll_percent=0.85)
        bandwidth = librosa.feature.spectral_bandwidth(y=audio, sr=sr)

        return {
            'centroide_media': float(np.mean(centroide)),
            'centroide_std': float(np.std(centroide)),
            'rolloff_media': float(np.mean(rolloff)),
            'rolloff_std': float(np.std(rolloff)),
            'bandwidth_media': float(np.mean(bandwidth)),
            'bandwidth_std': float(np.std(bandwidth))
        }

class AnalisadorTemporal:
    """Analisa ADSR, timing, jitter e shimmer"""

    def analisar_adsr(self, audio, sr):
        """Analisa envelope ADSR"""
        envelope = np.abs(librosa.onset.onset_strength(y=audio, sr=sr))

        if len(envelope) == 0:
            return {'attack_time': 0, 'decay_time': 0, 'sustain_level': 0, 'release_time': 0}

        peak_idx = np.argmax(envelope)
        attack_time = peak_idx / sr * 512

        if peak_idx < len(envelope) - 1:
            sustain_level = np.mean(envelope[peak_idx:])
        else:
            sustain_level = envelope[peak_idx]

        return {
            'attack_time': float(attack_time),
            'sustain_level': float(sustain_level),
            'envelope_std': float(np.std(envelope))
        }

    def analisar_jitter_shimmer(self, audio, sr):
        """Analisa jitter e shimmer"""
        try:
            snd = parselmouth.Sound(audio, sampling_frequency=sr)
            point_process = call(snd, "To PointProcess (periodic, cc)", 75, 600)
            jitter_local = call(point_process, "Get jitter (local)", 0, 0, 0.0001, 0.02, 1.3)
            shimmer_local = call([snd, point_process], "Get shimmer (local)", 0, 0, 0.0001, 0.02, 1.3, 1.6)

            return {
                'jitter': float(jitter_local) if not np.isnan(jitter_local) else 0,
                'shimmer': float(shimmer_local) if not np.isnan(shimmer_local) else 0
            }
        except:
            return {'jitter': 0, 'shimmer': 0}

class AnalisadorQualidade:
    """Analisa HNR, breathiness, brilho e tens√£o vocal"""

    def calcular_hnr(self, audio, sr):
        """Calcula Harmonics-to-Noise Ratio"""
        try:
            snd = parselmouth.Sound(audio, sampling_frequency=sr)
            harmonicity = call(snd, "To Harmonicity (cc)", 0.01, 75, 0.1, 1.0)
            hnr = call(harmonicity, "Get mean", 0, 0)
            return float(hnr) if not np.isnan(hnr) else 0
        except:
            return 0

    def analisar_breathiness(self, audio, sr):
        """Analisa soprosidade"""
        stft = np.abs(librosa.stft(audio))
        freqs = librosa.fft_frequencies(sr=sr)

        mask_low = freqs < 1000
        energia_baixa = np.sum(stft[mask_low])

        mask_high = freqs > 4000
        energia_alta = np.sum(stft[mask_high])

        if energia_baixa > 0:
            breathiness = energia_alta / energia_baixa
        else:
            breathiness = 0

        return {
            'breathiness_ratio': float(breathiness),
            'nivel': 'alto' if breathiness > 0.3 else 'medio' if breathiness > 0.1 else 'baixo'
        }

    def analisar_brilho_espectral(self, audio, sr):
        """Analisa brilho"""
        spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)
        brilho_medio = np.mean(spectral_centroid)

        return {
            'brilho_hz': float(brilho_medio),
            'nivel': 'brilhante' if brilho_medio > 2000 else 'medio' if brilho_medio > 1000 else 'escuro'
        }

    def analisar_tensao_vocal(self, audio, sr):
        """Analisa tens√£o vocal"""
        stft = np.abs(librosa.stft(audio))
        freqs = librosa.fft_frequencies(sr=sr)

        mask_tensao = (freqs > 2000) & (freqs < 4000)
        energia_tensao = np.sum(stft[mask_tensao])
        energia_total = np.sum(stft)

        if energia_total > 0:
            ratio_tensao = energia_tensao / energia_total
        else:
            ratio_tensao = 0

        return {
            'tensao_ratio': float(ratio_tensao),
            'nivel': 'alta' if ratio_tensao > 0.3 else 'media' if ratio_tensao > 0.15 else 'baixa'
        }

class AnalisadorDinamico:
    """Analisa amplitude, volume e transi√ß√µes de registro"""

    def analisar_dinamica(self, audio, sr):
        """Analisa varia√ß√µes de amplitude/volume"""
        rms = librosa.feature.rms(y=audio)[0]
        db = librosa.amplitude_to_db(rms, ref=np.max)

        return {
            'rms_media': float(np.mean(rms)),
            'rms_std': float(np.std(rms)),
            'db_media': float(np.mean(db)),
            'db_std': float(np.std(db)),
            'db_min': float(np.min(db)),
            'db_max': float(np.max(db)),
            'range_dinamico': float(np.max(db) - np.min(db))
        }

    def detectar_transicoes_registro(self, f0):
        """Detecta transi√ß√µes entre registros vocais"""
        f0_clean = f0[~np.isnan(f0)]

        if len(f0_clean) < 10:
            return {'transicoes': [], 'numero_transicoes': 0}

        diff = np.diff(f0_clean)
        threshold = np.std(diff) * 2
        transicoes = np.where(np.abs(diff) > threshold)[0]

        return {
            'numero_transicoes': len(transicoes),
            'transicoes': transicoes.tolist()[:10]
        }

class AnalisadorProsodico:
    """Analisa inflex√µes, portamentos e articula√ß√£o"""

    def analisar_portamentos(self, f0, sr):
        """Detecta deslizamentos entre notas"""
        f0_clean = f0[~np.isnan(f0)]

        if len(f0_clean) < 10:
            return {'portamentos_detectados': 0, 'duracao_media': 0}

        diff = np.diff(f0_clean)
        gradientes = np.gradient(diff)

        portamentos = []
        in_portamento = False
        duracao_atual = 0

        for i, g in enumerate(gradientes):
            if abs(g) > 1 and abs(g) < 10:
                if not in_portamento:
                    in_portamento = True
                    duracao_atual = 1
                else:
                    duracao_atual += 1
            else:
                if in_portamento and duracao_atual > 5:
                    portamentos.append(duracao_atual)
                in_portamento = False
                duracao_atual = 0

        if portamentos:
            duracao_media = np.mean(portamentos) * (512 / sr)
        else:
            duracao_media = 0

        return {
            'portamentos_detectados': len(portamentos),
            'duracao_media_segundos': float(duracao_media)
        }

    def analisar_articulacao(self, audio, sr):
        """Analisa padr√µes de articula√ß√£o"""
        onset_env = librosa.onset.onset_strength(y=audio, sr=sr)
        onsets = librosa.onset.onset_detect(onset_envelope=onset_env, sr=sr)

        if len(onsets) > 1:
            intervalos = np.diff(onsets) * (512 / sr)
            taxa_articulacao = 1 / np.mean(intervalos) if np.mean(intervalos) > 0 else 0
        else:
            taxa_articulacao = 0

        return {
            'onsets_detectados': len(onsets),
            'taxa_articulacao_por_segundo': float(taxa_articulacao)
        }

class AnalisadorRessonancia:
    """Analisa resson√¢ncia peitoral, mista, cabe√ßa, nasal e falsete"""

    def __init__(self):
        self.ranges_ressonancia = {
            'peitoral': (80, 350),
            'mista': (350, 600),
            'cabeca': (600, 1500),
            'nasal': (1500, 3000),
            'falsete': (800, 2000)
        }

    def analisar_frequencia_dominante(self, audio, sr, start_time, end_time):
        """Analisa frequ√™ncia dominante em um segmento"""
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)

        start_sample = max(0, start_sample)
        end_sample = min(len(audio), end_sample)

        segmento = audio[start_sample:end_sample]

        if len(segmento) < 100:
            return None, None

        try:
            fft = np.fft.fft(segmento)
            magnitude = np.abs(fft)
            freqs = np.fft.fftfreq(len(segmento), 1/sr)

            idx_pos = freqs > 0
            freqs = freqs[idx_pos]
            magnitude = magnitude[idx_pos]

            if len(freqs) == 0 or len(magnitude) == 0:
                return None, None

            freq_dominante = freqs[np.argmax(magnitude)]

            energia_por_faixa = {}
            for nome, (freq_min, freq_max) in self.ranges_ressonancia.items():
                mask = (freqs >= freq_min) & (freqs <= freq_max)
                energia_por_faixa[nome] = np.sum(magnitude[mask])

            return freq_dominante, energia_por_faixa

        except:
            return None, None

    def determinar_ressonancia(self, freq_dominante, energia_por_faixa):
        """Determina tipo de resson√¢ncia predominante"""
        if freq_dominante is None or energia_por_faixa is None:
            return "normal"

        energia_total = sum(energia_por_faixa.values())
        if energia_total == 0:
            return "normal"

        ressonancia_principal = max(energia_por_faixa, key=energia_por_faixa.get)
        percentual = energia_por_faixa[ressonancia_principal] / energia_total

        if percentual > 0.4:
            return ressonancia_principal
        else:
            return "mista"

    def obter_marcacao(self, ressonancia):
        """Retorna marca√ß√£o para o tipo de resson√¢ncia"""
        marcacoes = {
            'peitoral': '[PEITO]',
            'mista': '[MISTA]',
            'cabeca': '[CABE√áA]',
            'nasal': '[NASAL]',
            'falsete': '[FALSETE]',
            'normal': ''
        }
        return marcacoes.get(ressonancia, '')

class AnalisadorVocalCompleto:
    """Integra todos os analisadores"""

    def __init__(self):
        self.analisador_pitch = AnalisadorPitch()
        self.analisador_espectral = AnalisadorEspectral()
        self.analisador_temporal = AnalisadorTemporal()
        self.analisador_qualidade = AnalisadorQualidade()
        self.analisador_dinamico = AnalisadorDinamico()
        self.analisador_prosodico = AnalisadorProsodico()
        self.analisador_ressonancia = AnalisadorRessonancia()

    def analisar_segmento_completo(self, audio, sr, start_time, end_time):
        """Analisa todas as caracter√≠sticas de um segmento"""
        start_sample = int(start_time * sr)
        end_sample = int(end_time * sr)
        segmento = audio[start_sample:end_sample]

        if len(segmento) < 100:
            return {}

        resultado = {}

        f0, voiced_flag, voiced_probs = self.analisador_pitch.extrair_f0(segmento, sr)
        resultado['pitch'] = self.analisador_pitch.estatisticas_f0(f0)
        resultado['vibrato'] = self.analisador_pitch.analisar_vibrato(f0, sr)

        resultado['formantes'] = self.analisador_espectral.extrair_formantes(segmento, sr)
        resultado['mfcc'] = self.analisador_espectral.extrair_mfcc(segmento, sr)
        resultado['envelope_espectral'] = self.analisador_espectral.analisar_envelope_espectral(segmento, sr)

        resultado['adsr'] = self.analisador_temporal.analisar_adsr(segmento, sr)
        resultado['jitter_shimmer'] = self.analisador_temporal.analisar_jitter_shimmer(segmento, sr)

        resultado['hnr'] = self.analisador_qualidade.calcular_hnr(segmento, sr)
        resultado['breathiness'] = self.analisador_qualidade.analisar_breathiness(segmento, sr)
        resultado['brilho'] = self.analisador_qualidade.analisar_brilho_espectral(segmento, sr)
        resultado['tensao'] = self.analisador_qualidade.analisar_tensao_vocal(segmento, sr)

        resultado['dinamica'] = self.analisador_dinamico.analisar_dinamica(segmento, sr)
        resultado['transicoes_registro'] = self.analisador_dinamico.detectar_transicoes_registro(f0)

        resultado['portamentos'] = self.analisador_prosodico.analisar_portamentos(f0, sr)
        resultado['articulacao'] = self.analisador_prosodico.analisar_articulacao(segmento, sr)

        freq_dom, energia = self.analisador_ressonancia.analisar_frequencia_dominante(audio, sr, start_time, end_time)
        ressonancia = self.analisador_ressonancia.determinar_ressonancia(freq_dom, energia)
        resultado['ressonancia'] = {
            'tipo': ressonancia,
            'freq_dominante': float(freq_dom) if freq_dom else 0,
            'marcacao': self.analisador_ressonancia.obter_marcacao(ressonancia)
        }

        return resultado

print("‚úì Classes definidas!")

# ============================================================================
# FUN√á√ÉO: SEGMENTAR √ÅUDIO POR TEMPO
# ============================================================================
def segmentar_por_tempo(segments_whisper, max_duracao):
    """
    Divide segmentos longos em peda√ßos menores baseado em max_duracao
    """
    segmentos_refinados = []

    for seg in segments_whisper:
        start = seg['start']
        end = seg['end']
        texto = seg['text'].strip()
        duracao = end - start

        if duracao <= max_duracao:
            # Segmento j√° √© pequeno o suficiente
            segmentos_refinados.append(seg)
        else:
            # Dividir em subsegmentos
            num_subseg = int(np.ceil(duracao / max_duracao))
            duracao_subseg = duracao / num_subseg

            # Dividir texto proporcionalmente
            palavras = texto.split()
            palavras_por_subseg = max(1, len(palavras) // num_subseg)

            for i in range(num_subseg):
                subseg_start = start + (i * duracao_subseg)
                subseg_end = min(end, start + ((i + 1) * duracao_subseg))

                # Pegar palavras correspondentes
                idx_inicio = i * palavras_por_subseg
                idx_fim = (i + 1) * palavras_por_subseg if i < num_subseg - 1 else len(palavras)
                subseg_texto = ' '.join(palavras[idx_inicio:idx_fim])

                segmentos_refinados.append({
                    'start': subseg_start,
                    'end': subseg_end,
                    'text': subseg_texto
                })

    return segmentos_refinados

# ============================================================================
# FUN√á√ÉO: GERAR RELAT√ìRIO PR√ÅTICO
# ============================================================================
def gerar_relatorio_pratico(analise_global):
    """Gera relat√≥rio orientado √† A√á√ÉO PR√ÅTICA"""

    rel = []

    rel.append("=" * 100)
    rel.append("GUIA PR√ÅTICO DE REPLICA√á√ÉO VOCAL - O QUE FAZER PARA IMITAR ESTA VOZ")
    rel.append("=" * 100)
    rel.append("")

    # 1. ALTURA DA VOZ
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 1. ALTURA DA VOZ (PITCH/TOM) - Qual nota cantar" + " " * 53 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    f0_media = analise_global['pitch']['media']
    f0_min = analise_global['pitch']['min']
    f0_max = analise_global['pitch']['max']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ F0 M√©dio: {f0_media:.1f} Hz")
    rel.append(f"   ‚Ä¢ Range: {f0_min:.1f} Hz a {f0_max:.1f} Hz")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")
    if f0_media < 150:
        rel.append(f"   ‚úì Esta √© uma VOZ GRAVE (Baixo/Contralto)")
        rel.append(f"   ‚úì Cante na regi√£o de D3-F3 (D√≥3 a F√°3)")
        rel.append(f"   ‚úì Use MAIS resson√¢ncia no PEITO")
        rel.append(f"   ‚úì Mantenha o som 'para baixo' e 'grosso'")
    elif f0_media < 250:
        rel.append(f"   ‚úì Esta √© uma VOZ M√âDIA (Bar√≠tono/Mezzo)")
        rel.append(f"   ‚úì Cante na regi√£o de A3-C4 (L√°3 a D√≥4)")
        rel.append(f"   ‚úì Use registro MISTO (meio peito, meio cabe√ßa)")
        rel.append(f"   ‚úì Balance resson√¢ncia entre peito e cabe√ßa")
    elif f0_media < 400:
        rel.append(f"   ‚úì Esta √© uma VOZ AGUDA (Tenor/Soprano)")
        rel.append(f"   ‚úì Cante na regi√£o de D4-F4 (D√≥4 a F√°4)")
        rel.append(f"   ‚úì Use MAIS voz de CABE√áA/MISTA")
        rel.append(f"   ‚úì Leve o som 'para cima' e 'para frente'")
    else:
        rel.append(f"   ‚úì Esta √© uma VOZ MUITO AGUDA")
        rel.append(f"   ‚úì Cante acima de F4 (F√°4)")
        rel.append(f"   ‚úì Use FALSETE ou voz de cabe√ßa pura")
        rel.append(f"   ‚úì Som leve e a√©reo")

    rel.append("")
    rel.append("üí° COMO PRATICAR:")
    rel.append("   1. Use um afinador de celular (apps: Tuner, Pano Tuner)")
    rel.append(f"   2. Cante uma nota sustentada tentando manter {f0_media:.0f} Hz")
    rel.append("   3. Ajuste at√© o afinador mostrar a frequ√™ncia correta")
    rel.append("")
    rel.append("")

    # 2. VIBRATO
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 2. VIBRATO - A 'tremidinha' na voz" + " " * 63 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    vibrato = analise_global['vibrato']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ Presente: {'SIM' if vibrato['presente'] else 'N√ÉO'}")
    if vibrato['presente']:
        rel.append(f"   ‚Ä¢ Taxa: {vibrato['taxa_hz']:.1f} Hz (oscila√ß√µes por segundo)")
        rel.append(f"   ‚Ä¢ Extens√£o: {vibrato['extensao_cents']:.1f} cents")
    rel.append("")

    if vibrato['presente']:
        if vibrato['taxa_hz'] < 4:
            velocidade = "LENTO"
            descricao = "ondula√ß√µes lentas e amplas"
        elif vibrato['taxa_hz'] < 6:
            velocidade = "M√âDIO"
            descricao = "oscila√ß√£o natural e equilibrada"
        else:
            velocidade = "R√ÅPIDO"
            descricao = "tremor r√°pido e intenso"

        rel.append(f"üéØ O QUE FAZER:")
        rel.append(f"   ‚úì Vibrato {velocidade}: {descricao}")
        rel.append(f"   ‚úì Fa√ßa cerca de {vibrato['taxa_hz']:.0f} oscila√ß√µes por segundo")

        if vibrato['extensao_cents'] < 50:
            rel.append(f"   ‚úì Vibrato SUTIL: varia√ß√£o pequena, quase impercept√≠vel")
        elif vibrato['extensao_cents'] < 100:
            rel.append(f"   ‚úì Vibrato MODERADO: varia√ß√£o natural")
        else:
            rel.append(f"   ‚úì Vibrato INTENSO: varia√ß√£o grande e expressiva")

        rel.append("")
        rel.append("üí° COMO PRATICAR:")
        rel.append("   1. Cante uma nota longa e sustentada")
        rel.append(f"   2. Fa√ßa pequenas oscila√ß√µes no tom, {vibrato['taxa_hz']:.0f} vezes por segundo")
        rel.append("   3. Use o diafragma: empurre levemente a barriga para dentro/fora no ritmo")
        rel.append("   4. OU relaxe a garganta e deixe oscilar naturalmente")
    else:
        rel.append(f"üéØ O QUE FAZER:")
        rel.append(f"   ‚úì N√ÉO use vibrato, ou use muito sutil")
        rel.append(f"   ‚úì Mantenha notas retas e firmes")
        rel.append("")
        rel.append("üí° COMO PRATICAR:")
        rel.append("   1. Cante notas longas sem oscilar")
        rel.append("   2. Mantenha o tom fixo, como uma flauta")

    rel.append("")
    rel.append("")

    # 3. FORMANTES
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 3. FORMANTES - Como moldar a 'COR' da voz (timbre √∫nico)" + " " * 42 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    rel.append(f"üìä DADOS T√âCNICOS:")
    if analise_global['formantes']:
        for i, formante in enumerate(analise_global['formantes'][:5], 1):
            if formante:
                media = formante.get(f'F{i}_media', 0)
                rel.append(f"   ‚Ä¢ F{i}: {media:.0f} Hz")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    # F1
    if analise_global['formantes'] and analise_global['formantes'][0]:
        f1 = analise_global['formantes'][0].get('F1_media', 0)
        rel.append(f"   F1 ({f1:.0f} Hz) - ABERTURA DA BOCA:")
        if f1 < 500:
            rel.append("      ‚úì Boca POUCO aberta, mand√≠bula relaxada")
            rel.append("      ‚úì Vogais mais fechadas (como 'i', 'u')")
        elif f1 < 800:
            rel.append("      ‚úì Boca MODERADAMENTE aberta")
            rel.append("      ‚úì Abertura natural, confort√°vel")
        else:
            rel.append("      ‚úì Boca BEM aberta, mand√≠bula baixa")
            rel.append("      ‚úì Vogais mais abertas (como 'a', '√©')")

    rel.append("")

    # F2
    if len(analise_global['formantes']) > 1 and analise_global['formantes'][1]:
        f2 = analise_global['formantes'][1].get('F2_media', 0)
        rel.append(f"   F2 ({f2:.0f} Hz) - POSI√á√ÉO DA L√çNGUA:")
        if f2 < 1200:
            rel.append("      ‚úì L√≠ngua para TR√ÅS, base elevada")
            rel.append("      ‚úì Som mais 'escuro' e 'grosso'")
            rel.append("      ‚úì Pense nas vogais 'o', 'u'")
        elif f2 < 2000:
            rel.append("      ‚úì L√≠ngua em posi√ß√£o NEUTRA/M√âDIA")
            rel.append("      ‚úì Som equilibrado")
        else:
            rel.append("      ‚úì L√≠ngua para FRENTE, ponta elevada")
            rel.append("      ‚úì Som mais 'claro' e 'brilhante'")
            rel.append("      ‚úì Pense nas vogais 'i', 'e'")

    rel.append("")

    # F3-F5
    rel.append("   F3-F5 - RESSON√ÇNCIA GERAL:")
    envelope = analise_global['envelope_espectral']
    centroide = envelope['centroide_media']

    if centroide < 1500:
        rel.append("      ‚úì Som ESCURO/AVELUDADO")
        rel.append("      ‚úì Mais resson√¢ncia no PEITO")
        rel.append("      ‚úì Direcione o som 'para baixo' e 'para tr√°s'")
    elif centroide < 2500:
        rel.append("      ‚úì Som EQUILIBRADO")
        rel.append("      ‚úì Balance resson√¢ncia entre peito e cabe√ßa")
    else:
        rel.append("      ‚úì Som BRILHANTE/CLARO")
        rel.append("      ‚úì Mais resson√¢ncia na M√ÅSCARA FACIAL")
        rel.append("      ‚úì Direcione o som 'para frente' e 'para cima'")

    rel.append("")
    rel.append("üí° COMO PRATICAR:")
    rel.append("   1. Grave sua voz e compare com a original")
    rel.append("   2. Experimente diferentes posi√ß√µes de l√≠ngua")
    rel.append("   3. Mude a abertura da boca")
    rel.append("   4. Use um espelho para observar")
    rel.append("")
    rel.append("")

    # 4. BREATHINESS
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 4. BREATHINESS - Quanto AR passa pela voz" + " " * 56 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    breathiness = analise_global['breathiness']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ N√≠vel: {breathiness['nivel'].upper()}")
    rel.append(f"   ‚Ä¢ Ratio: {breathiness['breathiness_ratio']:.3f}")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    if breathiness['nivel'] == 'alto':
        rel.append("   ‚úì VOZ COM MUITO AR (tipo Billie Eilish, Norah Jones)")
        rel.append("   ‚úì Deixe as cordas vocais MENOS fechadas")
        rel.append("   ‚úì Permita que MAIS ar escape enquanto canta")
        rel.append("   ‚úì Som 'sussurrado', √≠ntimo")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. N√£o force o fechamento da garganta")
        rel.append("   2. Cante como se estivesse sussurrando")
        rel.append("   3. Ou√ßa o 'shhh' do ar junto com a nota")
    elif breathiness['nivel'] == 'medio':
        rel.append("   ‚úì VOZ EQUILIBRADA")
        rel.append("   ‚úì Cordas vocais MODERADAMENTE fechadas")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Cante de forma natural e relaxada")
    else:
        rel.append("   ‚úì VOZ LIMPA E COMPRIMIDA (tipo Whitney Houston, Adele)")
        rel.append("   ‚úì Feche BEM as cordas vocais")
        rel.append("   ‚úì Permita que POUCO ar escape")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Comprima as cordas vocais ao cantar")
        rel.append("   2. Som 'fechado', potente")
        rel.append("   3. N√£o deve ouvir 'ar' junto com a nota")

    rel.append("")
    rel.append("")

    # 5. BRILHO
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 5. BRILHO - Som claro/escuro" + " " * 69 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    brilho = analise_global['brilho']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ N√≠vel: {brilho['nivel'].upper()}")
    rel.append(f"   ‚Ä¢ Centr√≥ide: {brilho['brilho_hz']:.0f} Hz")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    if brilho['nivel'] == 'brilhante':
        rel.append("   ‚úì VOZ CLARA/BRILHANTE (muita energia nos agudos)")
        rel.append("   ‚úì Direcione o som para a M√ÅSCARA FACIAL")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Imagine o som saindo pelo nariz/olhos")
        rel.append("   2. Sinta vibra√ß√£o na face (ma√ß√£s do rosto)")
        rel.append("   3. Som 'apontado', projetado")
    elif brilho['nivel'] == 'medio':
        rel.append("   ‚úì VOZ EQUILIBRADA")
        rel.append("   ‚úì Balance entre peito e cabe√ßa")
    else:
        rel.append("   ‚úì VOZ ESCURA/AVELUDADA (mais energia nos graves)")
        rel.append("   ‚úì Direcione o som para o PEITO")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Imagine o som saindo do peito")
        rel.append("   2. Sinta vibra√ß√£o no peito (coloque a m√£o)")
        rel.append("   3. Som 'redondo', cheio")

    rel.append("")
    rel.append("")

    # 6. TENS√ÉO
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 6. TENS√ÉO VOCAL - Voz apertada ou relaxada" + " " * 55 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    tensao = analise_global['tensao']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ N√≠vel: {tensao['nivel'].upper()}")
    rel.append(f"   ‚Ä¢ Ratio: {tensao['tensao_ratio']:.3f}")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    if tensao['nivel'] == 'alta':
        rel.append("   ‚úì VOZ TENSA/COMPRIMIDA")
        rel.append("   ‚úì Garganta mais FECHADA")
        rel.append("   ‚úì Som 'apertado', intenso")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Comprima a garganta levemente")
        rel.append("   2. Som mais 'metal', incisivo")
        rel.append("   ‚ö†Ô∏è  CUIDADO: N√£o force demais!")
    elif tensao['nivel'] == 'media':
        rel.append("   ‚úì TENS√ÉO MODERADA")
        rel.append("   ‚úì Equil√≠brio entre tenso e relaxado")
    else:
        rel.append("   ‚úì VOZ RELAXADA/ABERTA")
        rel.append("   ‚úì Garganta BEM aberta")
        rel.append("   ‚úì Som 'solto', natural")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Relaxe TODA a garganta")
        rel.append("   2. Como um bocejo: garganta aberta")
        rel.append("   3. Som 'f√°cil', fluido")

    rel.append("")
    rel.append("")

    # 7. ATAQUE
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 7. ATAQUE - Como come√ßar cada nota" + " " * 62 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    attack = analise_global['adsr']['attack_time']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ Attack Time: {attack:.4f} segundos")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    if attack < 0.05:
        rel.append("   ‚úì ATAQUE R√ÅPIDO/DURO")
        rel.append("   ‚úì Notas come√ßam IMEDIATAMENTE no volume m√°ximo")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Comece a nota com for√ßa IMEDIATA")
        rel.append("   2. Como um 'golpe' vocal: PAM!")
    elif attack < 0.15:
        rel.append("   ‚úì ATAQUE MODERADO")
        rel.append("   ‚úì Notas come√ßam rapidamente mas n√£o abruptamente")
    else:
        rel.append("   ‚úì ATAQUE SUAVE/LENTO")
        rel.append("   ‚úì Notas come√ßam GRADUALMENTE")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Comece a nota SUAVEMENTE")
        rel.append("   2. V√° CRESCENDO aos poucos")
        rel.append("   3. Como uma 'fade in' na voz")

    rel.append("")
    rel.append("")

    # 8. DIN√ÇMICA
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 8. DIN√ÇMICA - Varia√ß√µes de volume (forte/fraco)" + " " * 50 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    dinamica = analise_global['dinamica']
    range_din = dinamica['range_dinamico']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ Range Din√¢mico: {range_din:.1f} dB")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    if range_din > 40:
        rel.append("   ‚úì MUITA VARIA√á√ÉO de volume")
        rel.append("   ‚úì Cante partes MUITO FORTES e partes MUITO FRACAS")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Identifique onde a pessoa canta FORTE")
        rel.append("   2. Identifique onde canta FRACO")
        rel.append("   3. Exagere o contraste")
    elif range_din > 25:
        rel.append("   ‚úì VARIA√á√ÉO MODERADA")
        rel.append("   ‚úì Algumas partes mais fortes, outras mais fracas")
    else:
        rel.append("   ‚úì POUCA VARIA√á√ÉO (volume constante)")
        rel.append("   ‚úì Mantenha volume UNIFORME")

    rel.append("")
    rel.append("")

    # 9. PORTAMENTOS
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 9. PORTAMENTOS - Deslizes entre notas" + " " * 60 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    portamentos = analise_global['portamentos']
    n_port = portamentos['portamentos_detectados']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ Portamentos: {n_port}")
    rel.append("")

    rel.append("üéØ O QUE FAZER:")

    if n_port > 20:
        rel.append("   ‚úì MUITOS DESLIZES (estilo melism√°tico)")
        rel.append("   ‚úì Escorregue/deslize entre QUASE TODAS as notas")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. N√ÉO pule direto de uma nota para outra")
        rel.append("   2. DESLIZE suavemente")
        rel.append("   3. Como uma sirene: uuuuuuuuuu")
    elif n_port > 5:
        rel.append("   ‚úì DESLIZES MODERADOS")
        rel.append("   ‚úì Algumas conex√µes legato")
    else:
        rel.append("   ‚úì POUCOS/SEM DESLIZES")
        rel.append("   ‚úì Pule DIRETAMENTE de nota para nota")
        rel.append("")
        rel.append("üí° COMO FAZER:")
        rel.append("   1. Corte seco entre notas")
        rel.append("   2. Cada nota √© separada: ta-ta-ta")

    rel.append("")
    rel.append("")

    # 10. QUALIDADE
    rel.append("‚îå" + "‚îÄ" * 98 + "‚îê")
    rel.append("‚îÇ 10. QUALIDADE GERAL DA VOZ" + " " * 71 + "‚îÇ")
    rel.append("‚îî" + "‚îÄ" * 98 + "‚îò")
    rel.append("")

    hnr = analise_global['hnr']

    rel.append(f"üìä DADOS T√âCNICOS:")
    rel.append(f"   ‚Ä¢ HNR: {hnr:.1f} dB")
    rel.append("")

    rel.append("üéØ RESULTADO:")
    if hnr > 15:
        rel.append("   ‚úì Voz muito LIMPA e CLARA")
        rel.append("   ‚úì Pouco ru√≠do, som cristalino")
    elif hnr > 8:
        rel.append("   ‚úì Voz EQUILIBRADA")
        rel.append("   ‚úì Clareza natural")
    else:
        rel.append("   ‚úì Voz mais ROUCA ou A√âREA")
        rel.append("   ‚úì Mais ru√≠do misturado com harm√¥nicos")

    rel.append("")
    rel.append("=" * 100)

    return "\n".join(rel)

# ============================================================================
# FUN√á√ÉO PRINCIPAL
# ============================================================================
def transcrever_e_analisar(audio_path, model_size='medium', segmentacao_tempo=3.0):
    """Transcreve e analisa com segmenta√ß√£o controlada"""

    print(f"\n{'='*80}")
    print("SISTEMA DE AN√ÅLISE VOCAL COMPLETA")
    print(f"{'='*80}")

    # CARREGAR MODELO
    print(f"\n[1/5] Carregando modelo Whisper ({model_size})...")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model = whisper.load_model(model_size, device=device)

    # DETECTAR IDIOMA
    print(f"\n[2/5] Detectando idioma...")
    audio_temp = whisper.load_audio(audio_path)
    audio_temp = whisper.pad_or_trim(audio_temp)
    mel = whisper.log_mel_spectrogram(audio_temp).to(model.device)
    _, probs = model.detect_language(mel)
    idioma = max(probs, key=probs.get)
    print(f"‚úì Idioma: {idioma.upper()}")

    # TRANSCREVER
    print(f"\n[3/5] Transcrevendo √°udio...")
    resultado = model.transcribe(
        audio_path,
        language=idioma,
        task='transcribe',
        verbose=False,
        word_timestamps=True
    )
    print(f"‚úì {len(resultado['segments'])} segmentos detectados")

    # SEGMENTAR
    print(f"\n[4/5] Aplicando segmenta√ß√£o de {segmentacao_tempo}s...")
    segmentos_refinados = segmentar_por_tempo(resultado['segments'], segmentacao_tempo)
    print(f"‚úì {len(segmentos_refinados)} segmentos ap√≥s refinamento")

    # CARREGAR √ÅUDIO
    print(f"\n[5/5] Analisando caracter√≠sticas vocais...")
    audio, sr = librosa.load(audio_path, sr=None)
    analisador = AnalisadorVocalCompleto()

    # AN√ÅLISE GLOBAL
    analise_global = analisador.analisar_segmento_completo(audio, sr, 0, len(audio)/sr)

    # GERAR RELAT√ìRIOS
    relatorio_pratico = gerar_relatorio_pratico(analise_global)

    # RELAT√ìRIO T√âCNICO
    relatorio_tecnico = []
    relatorio_tecnico.append("="*100)
    relatorio_tecnico.append("AN√ÅLISE T√âCNICA DETALHADA POR SEGMENTO")
    relatorio_tecnico.append("="*100)
    relatorio_tecnico.append(f"Segmenta√ß√£o: {segmentacao_tempo}s por segmento")
    relatorio_tecnico.append(f"Total de segmentos: {len(segmentos_refinados)}")
    relatorio_tecnico.append("="*100)
    relatorio_tecnico.append("")

    # ANALISAR CADA SEGMENTO
    for i, seg in enumerate(segmentos_refinados, 1):
        if i % 5 == 0:
            print(f"  Analisando segmento {i}/{len(segmentos_refinados)}...")

        analise_seg = analisador.analisar_segmento_completo(audio, sr, seg['start'], seg['end'])

        relatorio_tecnico.append(f"\n[{seg['start']:.2f}s - {seg['end']:.2f}s] {seg['text']}")
        relatorio_tecnico.append("-" * 100)

        # 1. PITCH (F0)
        if analise_seg.get('pitch'):
            p = analise_seg['pitch']
            f0_media_seg = p['media']

            # Classifica√ß√£o do tom
            if f0_media_seg < 150:
                tom_desc = "GRAVE"
            elif f0_media_seg < 250:
                tom_desc = "M√âDIO"
            elif f0_media_seg < 400:
                tom_desc = "AGUDO"
            else:
                tom_desc = "MUITO AGUDO"

            relatorio_tecnico.append(f"  1Ô∏è‚É£ PITCH: {p['media']:.1f} Hz ({tom_desc}) | Range: {p['min']:.1f}-{p['max']:.1f} Hz")

        # 2. VIBRATO
        if analise_seg.get('vibrato'):
            v = analise_seg['vibrato']
            if v.get('presente'):
                # Classificar velocidade
                if v['taxa_hz'] < 4:
                    vel_vib = "LENTO"
                elif v['taxa_hz'] < 6:
                    vel_vib = "M√âDIO"
                else:
                    vel_vib = "R√ÅPIDO"

                # Classificar intensidade
                if v['extensao_cents'] < 50:
                    int_vib = "sutil"
                elif v['extensao_cents'] < 100:
                    int_vib = "moderado"
                else:
                    int_vib = "intenso"

                relatorio_tecnico.append(f"  2Ô∏è‚É£ VIBRATO: {v['taxa_hz']:.1f} Hz ({vel_vib}), {v['extensao_cents']:.1f} cents ({int_vib})")
            else:
                relatorio_tecnico.append(f"  2Ô∏è‚É£ VIBRATO: Ausente ou muito sutil")

        # 3. FORMANTES (F1 e F2)
        if analise_seg.get('formantes'):
            formantes_seg = analise_seg['formantes']
            if len(formantes_seg) >= 2:
                f1_val = formantes_seg[0].get('F1_media', 0)
                f2_val = formantes_seg[1].get('F2_media', 0)

                if f1_val > 0 and f2_val > 0:
                    # Interpreta√ß√£o de F1 (abertura da boca)
                    if f1_val < 500:
                        f1_desc = "boca FECHADA"
                        f1_acao = "mand√≠bula relaxada"
                    elif f1_val < 800:
                        f1_desc = "boca M√âDIA"
                        f1_acao = "abertura natural"
                    else:
                        f1_desc = "boca ABERTA"
                        f1_acao = "mand√≠bula baixa"

                    # Interpreta√ß√£o de F2 (posi√ß√£o da l√≠ngua)
                    if f2_val < 1200:
                        f2_desc = "l√≠ngua TR√ÅS"
                        f2_acao = "som escuro"
                    elif f2_val < 2000:
                        f2_desc = "l√≠ngua CENTRO"
                        f2_acao = "som equilibrado"
                    else:
                        f2_desc = "l√≠ngua FRENTE"
                        f2_acao = "som brilhante"

                    relatorio_tecnico.append(f"  3Ô∏è‚É£ FORMANTES: F1={f1_val:.0f}Hz ({f1_desc}, {f1_acao}) | F2={f2_val:.0f}Hz ({f2_desc}, {f2_acao})")
                else:
                    relatorio_tecnico.append(f"  3Ô∏è‚É£ FORMANTES: N√£o detectados neste segmento")
            else:
                relatorio_tecnico.append(f"  3Ô∏è‚É£ FORMANTES: Dados insuficientes")
        else:
            relatorio_tecnico.append(f"  3Ô∏è‚É£ FORMANTES: N√£o analisados")

        # 4. BREATHINESS (AR NA VOZ)
        if analise_seg.get('breathiness'):
            b = analise_seg['breathiness']
            breath_nivel = b['nivel'].upper()
            breath_ratio = b['breathiness_ratio']

            if breath_nivel == 'ALTO':
                breath_acao = "deixe MUITO ar passar, cante sussurrado"
            elif breath_nivel == 'MEDIO':
                breath_acao = "ar moderado, natural"
            else:
                breath_acao = "POUCO ar, voz limpa e comprimida"

            relatorio_tecnico.append(f"  4Ô∏è‚É£ BREATHINESS: {breath_nivel} (ratio: {breath_ratio:.3f}) ‚Üí {breath_acao}")

        # 5. BRILHO
        if analise_seg.get('brilho'):
            br = analise_seg['brilho']
            brilho_nivel = br['nivel'].upper()
            brilho_hz = br['brilho_hz']

            if brilho_nivel == 'BRILHANTE':
                brilho_acao = "som para FRENTE, m√°scara facial"
            elif brilho_nivel == 'MEDIO':
                brilho_acao = "som equilibrado"
            else:
                brilho_acao = "som para TR√ÅS, resson√¢ncia no peito"

            relatorio_tecnico.append(f"  5Ô∏è‚É£ BRILHO: {brilho_nivel} ({brilho_hz:.0f} Hz) ‚Üí {brilho_acao}")

        # 6. TENS√ÉO VOCAL
        if analise_seg.get('tensao'):
            t = analise_seg['tensao']
            tensao_nivel = t['nivel'].upper()
            tensao_ratio = t['tensao_ratio']

            if tensao_nivel == 'ALTA':
                tensao_acao = "garganta FECHADA, som apertado"
            elif tensao_nivel == 'MEDIA':
                tensao_acao = "tens√£o equilibrada"
            else:
                tensao_acao = "garganta ABERTA, som relaxado"

            relatorio_tecnico.append(f"  6Ô∏è‚É£ TENS√ÉO: {tensao_nivel} (ratio: {tensao_ratio:.3f}) ‚Üí {tensao_acao}")

        # 7. ATAQUE DAS NOTAS
        if analise_seg.get('adsr'):
            adsr = analise_seg['adsr']
            attack = adsr['attack_time']

            if attack < 0.05:
                attack_desc = "DURO/R√ÅPIDO"
                attack_acao = "comece a nota COM FOR√áA imediata"
            elif attack < 0.15:
                attack_desc = "MODERADO"
                attack_acao = "comece firme mas n√£o abrupto"
            else:
                attack_desc = "SUAVE/LENTO"
                attack_acao = "comece SUAVEMENTE, cres√ßa aos poucos"

            relatorio_tecnico.append(f"  7Ô∏è‚É£ ATAQUE: {attack:.3f}s ({attack_desc}) ‚Üí {attack_acao}")

        # 8. DIN√ÇMICA (VOLUME)
        if analise_seg.get('dinamica'):
            d = analise_seg['dinamica']
            db_media = d['db_media']
            range_din = d['range_dinamico']

            # Classificar volume absoluto
            if db_media > -10:
                vol_desc = "MUITO FORTE"
            elif db_media > -20:
                vol_desc = "FORTE"
            elif db_media > -30:
                vol_desc = "M√âDIO"
            else:
                vol_desc = "FRACO"

            # Classificar varia√ß√£o
            if range_din > 40:
                var_desc = "MUITA varia√ß√£o"
            elif range_din > 25:
                var_desc = "varia√ß√£o moderada"
            else:
                var_desc = "volume constante"

            relatorio_tecnico.append(f"  8Ô∏è‚É£ DIN√ÇMICA: {db_media:.1f} dB ({vol_desc}) | Range: {range_din:.1f} dB ({var_desc})")

        # 9. PORTAMENTOS (DESLIZES)
        if analise_seg.get('portamentos'):
            port = analise_seg['portamentos']
            num_port = port['portamentos_detectados']

            if num_port > 5:
                port_desc = "MUITOS deslizes"
                port_acao = "escorregue entre as notas (glissando)"
            elif num_port > 2:
                port_desc = "alguns deslizes"
                port_acao = "deslize ocasionalmente"
            else:
                port_desc = "POUCOS/SEM deslizes"
                port_acao = "pule DIRETO de nota para nota"

            relatorio_tecnico.append(f"  9Ô∏è‚É£ PORTAMENTOS: {num_port} detectados ({port_desc}) ‚Üí {port_acao}")

        # 10. QUALIDADE GERAL (HNR)
        if analise_seg.get('hnr') is not None:
            hnr = analise_seg['hnr']

            if hnr > 15:
                hnr_desc = "voz MUITO LIMPA"
                hnr_acao = "som cristalino, pouco ru√≠do"
            elif hnr > 8:
                hnr_desc = "voz EQUILIBRADA"
                hnr_acao = "clareza natural"
            else:
                hnr_desc = "voz ROUCA/A√âREA"
                hnr_acao = "mais ru√≠do misturado"

            relatorio_tecnico.append(f"  üîü QUALIDADE: HNR {hnr:.1f} dB ({hnr_desc}) ‚Üí {hnr_acao}")

        # RESSON√ÇNCIA (B√îNUS)
        if analise_seg.get('ressonancia'):
            r = analise_seg['ressonancia']
            res_tipo = r['tipo'].upper()
            res_freq = r['freq_dominante']

            res_descricoes = {
                'PEITORAL': 'grave, vibra√ß√£o no peito',
                'MISTA': 'transi√ß√£o entre registros',
                'CABECA': 'agudo, resson√¢ncia na cabe√ßa',
                'NASAL': 'resson√¢ncia nasal',
                'FALSETE': 'leve e a√©reo'
            }

            res_desc = res_descricoes.get(res_tipo, 'normal')
            relatorio_tecnico.append(f"  ‚ûï RESSON√ÇNCIA: {res_tipo} ({res_freq:.0f} Hz) - {res_desc}")

        # Linha em branco para separa√ß√£o
        relatorio_tecnico.append("")

    print(f"‚úì An√°lise completa!")

    # COMBINAR RELAT√ìRIOS
    relatorio_final = relatorio_pratico + "\n\n\n" + "\n".join(relatorio_tecnico)

    return relatorio_final, analise_global

print("‚úì Fun√ß√µes definidas!")

# ============================================================================
# EXECUTAR AN√ÅLISE
# ============================================================================
print("\n" + "="*80)
print("EXECUTANDO AN√ÅLISE VOCAL COMPLETA")
print("="*80)

try:
    if not os.path.exists(AUDIO_PATH):
        print(f"\n‚ùå ERRO: Arquivo n√£o encontrado: {AUDIO_PATH}")
    else:
        resultado_final, dados_globais = transcrever_e_analisar(
            AUDIO_PATH,
            MODEL_SIZE,
            SEGMENTACAO_TEMPO
        )

        # SALVAR
        output_path = AUDIO_PATH.replace('.wav', '_analise_pratica.txt')
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(resultado_final)

        print(f"\n{'='*80}")
        print(f"‚úì Arquivo salvo: {output_path}")
        print(f"{'='*80}")

        # MOSTRAR PR√âVIA
        print("\n" + "="*80)
        print("PR√âVIA DO RELAT√ìRIO PR√ÅTICO:")
        print("="*80)
        print(resultado_final[:2000] + "\n...\n(arquivo completo salvo)")

        print("\n‚úÖ AN√ÅLISE COMPLETA FINALIZADA COM SUCESSO!")

except Exception as e:
    print(f"\n‚ùå ERRO: {str(e)}")
    import traceback
    traceback.print_exc()

print("\n" + "="*80)
print("üì• Arquivo gerado est√° no seu Google Drive!")
print("="*80)